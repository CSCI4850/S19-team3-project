{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we need to read in our data set which can be found in ______. To read the information from the file, we will need to enlist the help of pandas. Using pandas, you can read files from both local files and the internet! Pretty neat, right? Let's import that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading data sets\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to be able to save this information in a way that is organized like the original data set. An array will suffice, with each row representing an individual student and each column representing an individual feature (like school and final grade). Numpy provides us with a way to create such an array and more functionality that will prove to be quite useful in our endeavors. Let's import that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For lots of awesome things\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's time to read in the data! We're going to save it in an array called \"student_data.\" We need to tell pandas the file we want to read from, how the information is seperated, or delimited, (it's seperated by semicolons \";\") and if there is a header, which there is. If you look at the file, you will see that the first row, row 0, tells us what can be found in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in student data\n",
    "student_data = np.array(pandas.read_table(\"./student-por.csv\",\n",
    "delimiter=\";\", header=0))\n",
    "\n",
    "# Display student data\n",
    "student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Later, we will need to know what each feature(column) represents. Let's import those descriptions now. We only need to read in one row but we need to let pandas know not to ignore the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptions for each feature (found in the header)\n",
    "feature_descrips = np.array(pandas.read_csv(\"./student-por.csv\",\n",
    "delimiter=\";\", header=None, nrows=1))\n",
    "\n",
    "# Display descriptions\n",
    "print(feature_descrips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hm..those descripriptions aren't very specific. Let's store some more detailed information. These descriptions were constructed using the description of attributes in Table 1 of Cortez and Silva's report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed descriptions\n",
    "feature_descrips = np.array([\"School\", \"Sex\", \"Age\", \"Urban or Rural Address\", \"Family Size\", \n",
    "                             \"Parent's Cohabitation status\", \"Mother's Education\", \"Father's Education\",\n",
    "                             \"Mother's Job\", \"Father's Job\", \"Reason for Choosing School\", \n",
    "                             \"Student's Gaurdain\", \"Home to School Travel Time\", \"Weekly Study Time\",\n",
    "                             \"Number of Past Class Failures\", \"Extra Educational Support\", \n",
    "                             \"Family Educational Support\", \"Extra Paid Classes\", \"Extra Curricular Activities\",\n",
    "                             \"Attended Nursery School\", \"Wants to Take Higher Education\", \"Internet Access at Home\", \n",
    "                             \"In a Romantic Relationship\", \"Quality of Family Relationships\",\n",
    "                             \"Free Time After School\", \"Time Spent Going out With Friends\", \n",
    "                             \"Workday Alcohol Consumption\", \"Weekend Alcohol Consumption\", \n",
    "                             \"Current Health Status\", \"Number of Student Absences\", \"First Period Grade\",\n",
    "                             \"Second Period Grade\", \"Final Grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Woohoo! Now we have all the information we need. Don't get too excited, though. We can't start building and training our neural net yet. We need to tidy up the data to make it easier for our net to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data is split by school, meaning all the students represented in the first part of this data set went to one school (GP - Gabriel Pereira ) and the rest went to another (MS - Mousinho da Silveira). This isn't ideal. We want our network to see student data from both schools and don't want it to get used to only seeing one. Let's shuffle the data. I told you numpy would come in handy again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data!\n",
    "np.random.shuffle(student_data)\n",
    "student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerically Classify Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we're going to classify the grades. Currently, each student has a final frade between 0 and 19, inclusive. We're going to classify them like letter grades, with 4 representing an A and 0 represeting an F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array holding final scores for every student\n",
    "scores = student_data[:,32]\n",
    "\n",
    "# Iterate through list of scores, changing them from a 0-19 value\n",
    "## to a 0-4 value (representing F-A)\n",
    "for i in range(len(scores)):\n",
    "    if(scores[i] > 18):\n",
    "        scores[i] = 4\n",
    "    elif(scores[i] > 16):\n",
    "        scores[i] = 3\n",
    "    elif(scores[i] > 14):\n",
    "        scores[i] = 2\n",
    "    elif(scores[i] > 12):\n",
    "        scores[i] = 1\n",
    "    else:\n",
    "        scores[i] = 0\n",
    "        \n",
    "# Update the final scores in student_data to reflect these changes\n",
    "for i in range(len(scores)):\n",
    "    student_data[i,32] = scores[i]\n",
    "    \n",
    "# Display new data. Hint: Look at the last column\n",
    "student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Non-Numeric Data to Integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at a student sample from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one student sample\n",
    "student_data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, several of our features have string values that don't mean much to our neural net. Let's encode these labels into integers using with sklearn's Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this for LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Label Encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Columns that hold non-numeric data\n",
    "indices = np.array([0,1,3,4,5,8,9,10,11,15,16,17,18,19,20,21,22])\n",
    "\n",
    "# Transform the non-numeric data in these columns to integers\n",
    "for i in range(len(indices)):\n",
    "    column = indices[i]\n",
    "    le.fit(student_data[:,column])\n",
    "    student_data[:,column] = le.transform(student_data[:,column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at what that student sample looks like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding 0's to -1 for Binomial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect, right? Well, not quite. When a neural net sees a feature has a value of 0, it takes it as there is no value which in turn will cause the weights (what drives our neural net) to not turn on. Let's fix that by changing the zeros in the binomial data to -1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that hold binomial data\n",
    "indices = np.array([0,1,3,4,5,15,16,17,18,19,20,21,22])\n",
    "\n",
    "# Change 0's to -1's\n",
    "for i in range(len(indices)):\n",
    "    column = indices[i]\n",
    "    \n",
    "    # values of current feature\n",
    "    feature = student_data[:,column]\n",
    "    \n",
    "    # change values to -1 if equal to 0\n",
    "    feature = np.where(feature==0, -1, feature)\n",
    "    student_data[:,column] = feature\n",
    "    \n",
    "student_data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Nominal and Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need our input to matter equally (Everyone is important!). We do this by standardizing our data (get a mean of 0 and a stardard deviation of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = student_data[:,[2,6,7,8,9,10,11,12,13,14,23,24,25,26,27,28,29,30,31]]\n",
    "print(student_data[0,:])\n",
    "Standardized = scaler.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean:', round(Standardized.mean()))\n",
    "print('Standard deviation:', Standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data[:,[2,6,7,8,9,10,11,12,13,14,23,24,25,26,27,28,29,30,31]] = Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encode Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our results are currently floating point numbers. We want to categorize them so the net views them as seperate values (or grades). To do this, we will one-hot encode them. This means that each grade will have an array of all zeroes except for one element, which will be a 1. This is kind of like the grade's ID. So for examples, F would be 10000 and D would be 01000. There are 5 unique grades [A-F] so there are 5 digits in each \"ID.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final grades\n",
    "results = student_data[:,32]\n",
    "\n",
    "# Take a look at first 5 final grades\n",
    "print(\"First 5 final grades:\", results[0:5])\n",
    "\n",
    "# All unique values for final grades (0-4 representing F-A)\n",
    "possible_results = np.unique(student_data[:,32]).T\n",
    "print(\"All possible results:\", possible_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras has an awesome built-in function that allows us to categorize the results in such a way. Keras is the library we will be using to build our network. Let's import it now so we can take advantage of its wonderful functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For building our net\n",
    "import keras\n",
    "\n",
    "# One-hot encode final grades (results) which will be used as our output\n",
    "# The length of the \"ID\" should be as long as the total number of possible results so each results\n",
    "## gets its own, personal one-hot encoding\n",
    "y = keras.utils.to_categorical(results,len(possible_results))\n",
    "\n",
    "# Take a look at the first 5 final grades now (no longer numbers but arrays)\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We set these categorized results equal to y because this is the -output- of our neural net which is intaking all features except the final grade. We shall call the set of these -inputs- x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our input, all features except final grades\n",
    "x = student_data[:,0:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's create a function that will build a model for us. This will come in handy later on. Our model will have two hidden layers. The first hidden layer will have an input size of 800, and the second will have an input size of 400. The optimizer that we are using is adamax which is good at ignoring noise in a datset. The loss function we are using is called categorical cross entropy and which is useful for trying to classify or label something. In this case, we are trying to classify students by letter grades, so this loss function will be of great use to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create network given model\n",
    "def create_network(model):\n",
    "    # Specify input/output size\n",
    "    input_size = x.shape[1]\n",
    "    output_size = y.shape[1]\n",
    "\n",
    "    # Creeate the hidden layer\n",
    "    model.add(keras.layers.Dense(800, input_dim = input_size, activation = 'relu'))\n",
    "\n",
    "    # Additional hidden layer\n",
    "    model.add(keras.layers.Dense(400,activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(keras.layers.Dense(output_size,activation='softmax'))\n",
    "\n",
    "    # Compile - why using adamax?\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adamax', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can create a basic model and have that function build the network for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-forward model\n",
    "model = keras.Sequential()\n",
    "create_network(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Test of the Network\n",
    "#### The initial model and its weights are included in the demo. We can import this model and the weights easily and skip the training. Before that we have to import some things that will be needed to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "\n",
    "# We have to import the model first\n",
    "model_file = open('./initial_model.json','r')\n",
    "model_json = model_file.read()\n",
    "model_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# After the model is imported we can import the weights\n",
    "loaded_model.load_weights(\"initial_model_weights.h5\")\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',optimizer='adamax',metrics=['accuracy'])\n",
    "print(\"Model is loaded and ready\")\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's see what this net can do! Before we do that, though, we need to split our data into to groups: one for training (our network will see this data and \"learn\" it) and one for testing. The testing data is data the network hasn't seen before. Once we're done training, we'll feed it the the trained network and see how well it outputs what it is supposed to. 20% of the 649 individual student statistics (approximately 130) will be designated to the testng data group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing data\n",
    "x_train = x[0:518,:]\n",
    "x_test = x[519:649,:]\n",
    "\n",
    "y_train = y[0:518,:]\n",
    "y_test = y[519:649,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To train our neural network, we're going to use the fit() member function which we can access through the model we created. There are certain things we need to specify.\n",
    "#### - First we need to tell the model that it will fed the training input and should produce the training output. \n",
    "#### -Then we need to specify the batch size. In this case, it's 32 (the default value for batch size). This means the net will go through 32 samples before it updates any of the weights that drive it. \n",
    "#### - The number of epochs describes how many times we want the net to see all samples of our data. Our net will run through all of our data 7 times.\n",
    "#### - We set verbose to 0 because we don't care too much about the accuracy and loss rates at each epoch nor how long it takes for each epoch to run. We're concerned only about the end result so we're going to opt out of this.\n",
    "#### - Finally we have the validation split which is set to 0.2 (20%). This means 20% of the training data will actually be used for validation instead of training. The model sees and learns from the initial 80% of the data and then uses the validation data to get used to seeing new things and being able to recognize them (generalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on training data! \n",
    "# We're saving this information in the variable -history- so we can take a look at it later\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = 32, \n",
    "                    epochs = 7, \n",
    "                    verbose = 0, \n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's time to see how the neural net performs on our testing data (the data it has never seen before). We're going to use the -evaluate- function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate using data the network hasn't seen before (testing data)\n",
    "# Save this info in -score- so we can take a look at it\n",
    "score = model.evaluate(x_test,y_test, verbose=0)\n",
    "\n",
    "# Check it's effectiveness\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It'd be nice to see a more visual representation of how our training went, don't you think? Let's make a plot to do just that. Since we're going to be doing this several times, we're going to create a function that takes in the history of model training and plots the training accuracy and loss (shown in blue) and the validation accuracy and loss (shown in orange). Too plot, we're going to need to inport matplotlib.pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the data\n",
    "def plot(history):\n",
    "\n",
    "    plt.figure(1)\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc ='upper left')\n",
    "\n",
    "    # Summarize history for loss\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train','test'], loc ='upper left')\n",
    "\n",
    "    # Display plot\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put this function to good use and plot the current training and validation info that is stored in -history-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot current training and validation accuracy and loss\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Without Individual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few questions now come to mind. Are all of these features important? Would removing unimportant ones improve accuracy? What features are most essential to maintaining a good accuracy? To answer these questions, we're going to try trainining the network with all featues except one. Since we're going to be doing this for 32 features, let's make a general function we can call that takes the index of the feature we want to remove and trains the network with all the features except that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the effects of removing one feature on training\n",
    "def remove_and_analyze(feature):\n",
    "    # Told you those feature descriptions would be useful\n",
    "    print(\"Without feature\", feature, \":\", feature_descrips[feature])\n",
    "    \n",
    "    # Create feed-forward network\n",
    "    model = keras.Sequential()\n",
    "    create_network(model)\n",
    "    \n",
    "    # Remove feature from columns (axis 1)\n",
    "    x = np.delete(student_data, feature, axis = 1)\n",
    "    \n",
    "    # Split data into training and testing data\n",
    "    x_train = x[0:518,:]\n",
    "    x_test = x[519:649,:]\n",
    "    \n",
    "    # Train on training data!\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size = 32, \n",
    "                        epochs = 7, \n",
    "                        verbose = 0, \n",
    "                        validation_split = 0.2)\n",
    "    \n",
    "    # Validate using data the network hasn't seen before (testing data)\n",
    "    score = model.evaluate(x_test,y_test, verbose=0)\n",
    "    \n",
    "    # Check it's effectiveness\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    # Plot the data\n",
    "    plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we'll run this function 32 times (once for each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the effects of removing one feature on training\n",
    "# Do this for all input features\n",
    "for i in range(student_data.shape[1]-1):\n",
    "    remove_and_analyze(i)\n",
    "    print(\"\\n \\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Without Five Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We found that the removal of these five features individually produced results with better accuracy: 1) Internet access at home 2) Wants to take higher education 3) Father's job 4) Mother's job 5) Father's education. If removing them one at a time improves accuracy, what would happen if we removed them all at once? Let's try it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported Model\n",
    "#### The final model and its weights are included in the demo. We can import this model and the weights easily and skip the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to import the model first\n",
    "model_file = open('model.json','r')\n",
    "model_json = model_file.read()\n",
    "model_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "# After the model is imported we can import the weights\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy',optimizer='adamax',metrics=['accuracy'])\n",
    "print(\"Model is loaded and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's see how the imported model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the five features that most negatively impact accuracy\n",
    "x = np.delete(student_data, 21, axis = 1)\n",
    "x = np.delete(x, 20, axis = 1)\n",
    "x = np.delete(x, 9, axis = 1)\n",
    "x = np.delete(x, 8, axis = 1)\n",
    "x = np.delete(x, 7, axis = 1)\n",
    "\n",
    "\n",
    "# Create test data\n",
    "x_test = x[519:649,:]\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wow! That's a lot better! Our accuracy increased from 80% to 97.08%. We did this by removing the five features which negatively impacted the accuracy of our net. What about the features that were most beneficial in obtaining a good accuracy? In other words, the removal of which features caused the accuracy rate to decrease?\n",
    "\n",
    "#### The original study by Cortez and Silva had come to the conclusion that previous grades had the most impact on predicting student performance. However, our goal is not solely to predict student performance but to better understand how non-academic features affect it. The five non-academic features that had the most beneficial effect on our neural net are: 1) Family educational support 2) Reason for choosing school 3) Frequency of going out with friends 4) Amount of free time after school 5) Access to extra paid classes\n",
    "\n",
    "#### How do we intend to do that? For each feature, we'll seperate student samples into groups according to the value of the featue they exhibit. For example, for the feature \"family educational support,\" we'll divide the student samples according to whether the student has this support or not. We'll only save the final grades since grade distribution is what we'll be analyzing.\n",
    "\n",
    "#### Let's create a function that takes in an array of final grades (pertaining to students that exhibit a specific value of a feature) and prints a bar graph which displays what percentage of students received F's, D's, C's, B's, or A's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for analyzing the percent of students with each grade [F,D,C,B,A]\n",
    "def analyze(array):\n",
    "    \n",
    "    # To hold the total number of students with a certain final grade\n",
    "    # Index 0 - F. Index 4 - A\n",
    "    sums = np.array([0,0,0,0,0])\n",
    "    \n",
    "    # Iterate through array. Update sums according to whether a student got a final grade of a(n)\n",
    "    for i in range(len(array)):\n",
    "        # F\n",
    "        if(array[i]==0):\n",
    "            sums[0] += 1\n",
    "        # D\n",
    "        elif(array[i]==1):\n",
    "            sums[1] +=1\n",
    "        # C\n",
    "        elif(array[i]==2):\n",
    "            sums[2] +=1\n",
    "        # B\n",
    "        elif(array[i]==3):\n",
    "            sums[3] +=1\n",
    "        # A\n",
    "        else:\n",
    "            sums[4] += 1\n",
    "            \n",
    "    # Total number of students\n",
    "    total = sums[0] + sums[1] + sums[2] + sums[3] + sums[4]\n",
    "    \n",
    "    # Hold percentage of students with grade of [F,D,C,B,A]\n",
    "    percentages = np.array([sums[0]/total*100, \n",
    "                            sums[1]/total*100, \n",
    "                            sums[2]/total*100, \n",
    "                            sums[3]/total*100, \n",
    "                            sums[4]/total*100])\n",
    "    \n",
    "    # One bar for each of the 5 grades\n",
    "    x = np.array([1,2,3,4,5])\n",
    "    \n",
    "    # Descriptions for each bar. None on y-axis\n",
    "    plt.xticks(np.arange(6), ('', 'F', 'D', 'C', 'B','A'))\n",
    "    \n",
    "    # X axis - grades. Y axis - percentage of students with each grade\n",
    "    plt.bar(x,percentages)\n",
    "    plt.xlabel(\"Grades\")\n",
    "    plt.ylabel(\"Percentage of Students\")\n",
    "    \n",
    "    # Display bar graph\n",
    "    plt.show()\n",
    "    \n",
    "    # Display percentages\n",
    "    print(percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's analyze the distribution of grades among our top five non-academic features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family Educational Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's create the arrays we want to analyze. One with the final grades of students who do have family educational support and one with the final grades of students that don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array holding final grades of all students who have family educational support\n",
    "fam_sup = []\n",
    "# Array holding final grades of all students who have family educational support\n",
    "no_fam_sup = []\n",
    "\n",
    "# Iterate through all student samples\n",
    "for i in range(student_data.shape[0]):\n",
    "    \n",
    "    # Does the student have family educational support? (-1 no, 1 yes)\n",
    "    sup = student_data[i][16]\n",
    "    \n",
    "    # Append student's final grade to corresponding array\n",
    "    if(sup==1):\n",
    "        fam_sup.append(student_data[i][32])\n",
    "    else:\n",
    "        no_fam_sup.append(student_data[i][32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family Educational Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(fam_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Family Educational Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(no_fam_sup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surprisingly, there is not much of a difference in the distribution. Among students with family educational support, the amount of students who got an F was 2% less than among students without this support. However, this 2% seemed to float into the D-range. This does show that the support might prove helpful to some students but it is not as crucial to grade distribution overall.\n",
    "\n",
    "#### It's imporant to note that only 2 students in the entire date set achieved a final grade of an A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're going to take a similar approach for the next four features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reason for choosing school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each array holds the grades of students who chose to go to their school for that reason\n",
    "# Close to home\n",
    "reason1 = []\n",
    "# School reputation\n",
    "reason2 = []\n",
    "# Course prefrence\n",
    "reason3 = []\n",
    "# Other\n",
    "reason4 = []\n",
    "\n",
    "# Values that represent these unique reasons. They are not integer numbers like in the previous\n",
    "## example. They're floatig point numbers so we'll save them so we can compare them to the value\n",
    "## of this feature in each sample\n",
    "unique_reasons = np.unique(student_data[:,10])\n",
    "\n",
    "# Iterate through all student samples and append final grades to corresponding arrays \n",
    "for i in range(student_data.shape[0]):\n",
    "    \n",
    "    reason = student_data[i][10]\n",
    "   \n",
    "    if(reason==unique_reasons[0]):\n",
    "        reason1.append(student_data[i][32])\n",
    "    elif(reason==unique_reasons[1]):\n",
    "        reason2.append(student_data[i][32])\n",
    "    elif(reason==unique_reasons[2]):\n",
    "        reason3.append(student_data[i][32])\n",
    "    else:\n",
    "        reason4.append(student_data[i][32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason 1: Close to Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(reason1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason 2: School Reputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(reason2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason 3: Course Prefrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(reason3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason 4: Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(reason4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By far, the worst distribution of grades pertains to the students who chose their school based on course prefrence. Why could this be? Perhaps these students want to go to a school with supposedly easier classes and therefore are less motivated to perform better. Or perhaps they chose easier classes because they struggle academically. Either way, this is interesting because you would think that giving students the choice to choose their school based on the courses offered would motivate them to perform better.\n",
    "\n",
    "#### The next worst distribution belongs to the students who chose this school because it is close to home. This could be because there was no academic motivation behind this reason or maybe the student had no means of transportation to go to another school which opens up the possibility of other factors that could affect student performance.\n",
    "\n",
    "#### School reputation had a much more gradual distribution but by far students who chose a reason other than the aforementioned features did by far the best. They had the lowest percentage of F's and the highest percentage of C's and B's. One student got an A. The other student that got an A based their selection of school reputation. This begs the questions, why did these students pick their school and why do they seem to do so much better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Going Out With Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each array holds the grades of students who go out with friends for that specified amount of time \n",
    "# (1 - very low, 5 - very high)\n",
    "go_out1 = []\n",
    "go_out2 = []\n",
    "go_out3 = []\n",
    "go_out4 = []\n",
    "go_out5 = []\n",
    "\n",
    "# Floating point values representing frequency\n",
    "unique = np.unique(student_data[:,25])\n",
    "\n",
    "# Iterate through all student samples and append final grades to corresponding arrays \n",
    "for i in range(student_data.shape[0]):\n",
    "    \n",
    "    frequency = student_data[i][25]\n",
    "    \n",
    "    if(frequency==unique[0]):\n",
    "        go_out1.append(student_data[i][32])\n",
    "    elif(frequency==unique[1]):\n",
    "        go_out2.append(student_data[i][32])\n",
    "    elif(frequency==unique[2]):\n",
    "        go_out3.append(student_data[i][32])\n",
    "    elif(frequency==unique[3]):\n",
    "        go_out4.append(student_data[i][32])\n",
    "    else:\n",
    "        go_out5.append(student_data[i][32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(go_out1)\n",
    "analyze(go_out2)\n",
    "analyze(go_out3)\n",
    "analyze(go_out4)\n",
    "analyze(go_out5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From these results, we can see that it is important for students to spend some time with friends. Those who minimally went out with friends did the worst academically. None of them got B's or A's and 95.8% of them either got an F or a D. However, students with the most amount of time spent going out had the highest percentage of F's (66.4%)\n",
    "#### By far, the students who did the best ranked the amount of time spent going out with friends at a 2 (low). Grade distributions got worse as the amount of time students spent going out with friends increased.\n",
    "#### This shows that social activity is important for student success but it should be limited. The time these students are not spending going out is probably spent preparing for school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Time after School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each array holds the grades of students who have the specified amount of free time after school \n",
    "# (1 - very low, 5 - very high)\n",
    "free1 = []\n",
    "free2 = []\n",
    "free3 = []\n",
    "free4 = []\n",
    "free5 = []\n",
    "\n",
    "# Floating point values representing frequency\n",
    "unique = np.unique(student_data[:,24])\n",
    "\n",
    "# Iterate through all student samples and append final grades to corresponding arrays \n",
    "for i in range(student_data.shape[0]):\n",
    "   \n",
    "    frequency = student_data[i][24]\n",
    "    \n",
    "    if(frequency==unique[0]):\n",
    "        free1.append(student_data[i][32])\n",
    "    elif(frequency==unique[1]):\n",
    "        free2.append(student_data[i][32])\n",
    "    elif(frequency==unique[2]):\n",
    "        free3.append(student_data[i][32])\n",
    "    elif(frequency==unique[3]):\n",
    "        free4.append(student_data[i][32])\n",
    "    else:\n",
    "        free5.append(student_data[i][32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(free1)\n",
    "analyze(free2)\n",
    "analyze(free3)\n",
    "analyze(free4)\n",
    "analyze(free5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interesting...our results are very similar to that of our previous example. Overall, those with the least amount of free time did the worst but those with the most had the highest percentage of students with an F (67.6...very close to the previous 66.4). Those who did the best had the second-least amount of free time and performace seems to decreaese from there. There seems to be a sort of \"sweet-spot\" when it comes to free time and going out with friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Paid Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last feature to analyze...how sad this is coming to an end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array holding final grades of all students who have extra paid classes\n",
    "paid_class = []\n",
    "# Array holding final grades of all students who do not have extra paid classes\n",
    "no_paid_class = []\n",
    "\n",
    "# Iterate through all student samples and append final grades to corresponding arrays \n",
    "for i in range(student_data.shape[0]):\n",
    "    \n",
    "    paid = student_data[i][17]\n",
    "    \n",
    "    if(paid==1):\n",
    "        paid_class.append(student_data[i][32])\n",
    "    else:\n",
    "        no_paid_class.append(student_data[i][32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Paid Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(paid_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Extra Paid Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(no_paid_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Well, isn't this intriguing? One would think that those with extra paid classes would perform better than those without them but it seems that the opposite is the case. Are the students who are attending these classes not motivated to put in work outside of classes because they believe they have sufficient knowledge thanks to these classes? Or are have they been struggling academically to begin with and that's why they are in these classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We hope you found this dive into student data as fascinating as we did. Our students are our future and as such we should invest in them. This means more than just funding schools and after school programs. We need to be focusing on the right features and understand the consequences of them. This way, we can make the most informed decision that would best benefit our students."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
