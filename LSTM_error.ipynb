{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading data sets from the web.\n",
    "import pandas\n",
    "# For lots of great things.\n",
    "import numpy as np\n",
    "# To make our plots.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Because sympy and LaTeX make\n",
    "# everything look wonderful!\n",
    "from sympy import *\n",
    "init_printing(use_latex=True)\n",
    "from IPython.display import display\n",
    "# We will use this to check our implementation...\n",
    "from sklearn.decomposition import PCA\n",
    "# We will grab another data set using Keras\n",
    "# after we finish up with Iris...\n",
    "import keras\n",
    "# Need this for LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data = np.array(pandas.read_table(\"./student-por.csv\",\n",
    "delimiter=\";\", header=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAAVCAYAAACnvtv5AAAABHNCSVQICAgIfAhkiAAABDhJREFUaIHt2VuIlVUUB/CfNppmlJWiSJFJaBNGaqkIZg+mgSFU9hDUQ4VCYCFF0eXFQ1BpQSTdyC6YERFYJj5UmhGSVFhNlGmCFyZRx5pMuzAamT2sfZjjN9+5qMczmvOHYXPWf6+11/7Wvqy1hx78r/AGfsaA7nbkNMdVOIzZtXQej39xfxl+KpajDQexCx9hRg22b0+OVHKmF+bgS/yJv/AV7kbvWibQICzEGuxAB/aiBfNxQR11lmM3zq7m0CrsQ/8c7inx0XdgMZ7AK/gmcZVwUbL7h8qBeyvxe5LtRdiYZEurOd9A/I0v8DoW4DmsF37uFPOth86ExD9ayZmRYrctzuHmJANL0DeH71PBbi98jK14WvnA3ZS4bRhUIu+LlYm7udIEGoh+ZeSPCz9frJMObEKrCifOgmRgakZ+prjzWuUHrRrmiQUxBQXlA7c0cXNzuDGJ++QYxm8krhR+rq6jzvzEX18UZCN4HQ6J7VyKaRiM90QAbsBDIiCTqjjVLBbEIqyt0ndoarflcEXZNY5t8TQKM1P7XR111qV2WlHQVEIOEKt6k0gISjE+tQfEZTo6w6/FLfglI2/Cm/hJlTM6oT21l+RwI0psjsCPNdhrBB4QicO5uBqTRQAW1FFnfWqn5JEjxXZclcO9lLh/0gCT08BXiIzyMD7N0XtM7ODSXVlQ/qi8LXFbcH6JvA9W6MxIq+3yRqJNp1+H8QGGnACdjqTXBZOSkXdyuJcTdwDDM9xZIsvMftCJItDZbLOgfODOwIeJb0vjLsIPInVuTdzEvAl0M4aI5GqzKJHG1Vlnp/ieXVC8/FfkcAsT93kZo68mfl763ZSc2SgSm1IUVC4H+oj783uxUPbhfVyGDUk37yg9WXCxqG831FlnryilumCY+Cif5XB36dzSeSim+A+n3wMdeRRU+nu2grOl6Ccml71HT0a0iLkNqtaxRp3eIincWhSUJie7xUcZlaO4Jhm9vMRIKYrJyvbUHsRrZRwch7FigWxWfhdncavIJt+usX93YlhqD9VJZ5Sohb8tp7xMBOjSHK6YHNyXkU8XgfxNZEnVUFD5qDwnRzZGLKq9OidYxJJk744axq4XRsqfa2+dxfS6DHcsOkXcmfh7ioKmTId3MUsUelsy3FyxU54RdVyLuGtuFKtkNvaXGfhosFpkUBvEmd6cxusQ9c6uTP9iLZp7cZ8gzMCT4tTYjl9FonGtKFXaxEvT8eoUMV1847z8A3EU7REPvHkYLN7XWsW7W7t4BJ1QdopdUVB5xz2Ir0VSclAU3i/gwjL9W/A7zjsKH44Xo/G8OLraxaLZL+qtgiNLmePRIXZph0jQKuIR8WHH1jqLbsRAsRKrPXCfyrhXxGNytY79xI5aeaI9qgNmipJhaLWOpyj6i6thWa0KU8TDZs8/UrsXzeIYHd69bvSgB6c7/gPeiEDbe16eDQAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$\\left ( 649, \\quad 33\\right )$$"
      ],
      "text/plain": [
       "(649, 33)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding non-numeric data to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# School (binomial)\n",
    "le.fit(student_data[:,0])\n",
    "student_data[:,0] = le.transform(student_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex (binomial)\n",
    "le.fit(student_data[:,1])\n",
    "student_data[:,1] = le.transform(student_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address (binomial)\n",
    "le.fit(student_data[:,3])\n",
    "student_data[:,3] = le.transform(student_data[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Famsize (binomial)\n",
    "le.fit(student_data[:,4])\n",
    "student_data[:,4] = le.transform(student_data[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pstatus (binomial)\n",
    "le.fit(student_data[:,5])\n",
    "student_data[:,5] = le.transform(student_data[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mjob (nominal)\n",
    "le.fit(student_data[:,8])\n",
    "student_data[:,8] = le.transform(student_data[:,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fjob (nominal)\n",
    "le.fit(student_data[:,9])\n",
    "student_data[:,9] = le.transform(student_data[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reason (nominal)\n",
    "le.fit(student_data[:,10])\n",
    "student_data[:,10] = le.transform(student_data[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardian (nominal)\n",
    "le.fit(student_data[:,11])\n",
    "student_data[:,11] = le.transform(student_data[:,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schoolsup (binomial)\n",
    "le.fit(student_data[:,15])\n",
    "student_data[:,15] = le.transform(student_data[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# famsup (binomial)\n",
    "le.fit(student_data[:,16])\n",
    "student_data[:,16] = le.transform(student_data[:,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paid (binomial)\n",
    "le.fit(student_data[:,17])\n",
    "student_data[:,17] = le.transform(student_data[:,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activities (binomial)\n",
    "le.fit(student_data[:,18])\n",
    "student_data[:,18] = le.transform(student_data[:,18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nursery (binomial)\n",
    "le.fit(student_data[:,19])\n",
    "student_data[:,19] = le.transform(student_data[:,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher (binomial)\n",
    "le.fit(student_data[:,20])\n",
    "student_data[:,20] = le.transform(student_data[:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internet (binomial)\n",
    "le.fit(student_data[:,21])\n",
    "student_data[:,21] = le.transform(student_data[:,21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# romantic (binomial)\n",
    "le.fit(student_data[:,22])\n",
    "student_data[:,22] = le.transform(student_data[:,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 18, ..., 0, 11, 11],\n",
       "       [0, 0, 17, ..., 9, 11, 11],\n",
       "       [0, 0, 15, ..., 12, 13, 12],\n",
       "       ...,\n",
       "       [1, 0, 18, ..., 11, 12, 9],\n",
       "       [1, 1, 17, ..., 10, 10, 10],\n",
       "       [1, 1, 18, ..., 10, 11, 11]], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding 0's to -1 for binomial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surely there's a one line method to do this... right, Keras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = student_data[:,0]\n",
    "school = np.where(school==0, -1, school)\n",
    "student_data[:,0] = school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = student_data[:,1]\n",
    "sex = np.where(sex==0, -1, sex)\n",
    "student_data[:,1] = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = student_data[:,3]\n",
    "address = np.where(address==0, -1, address)\n",
    "student_data[:,3] = address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "famsize = student_data[:,4]\n",
    "famsize = np.where(famsize==0, -1, famsize)\n",
    "student_data[:,4] = famsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pstatus = student_data[:,5]\n",
    "Pstatus = np.where(Pstatus==0, -1, Pstatus)\n",
    "student_data[:,5] = Pstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolsup = student_data[:,15]\n",
    "schoolsup = np.where(schoolsup==0, -1, schoolsup)\n",
    "student_data[:,15] = schoolsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "famsup = student_data[:,16]\n",
    "famsup = np.where(famsup==0, -1, famsup)\n",
    "student_data[:,16] = famsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid = student_data[:,17]\n",
    "paid = np.where(paid==0, -1, paid)\n",
    "student_data[:,17] = paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = student_data[:,18]\n",
    "activities = np.where(activities==0, -1, activities)\n",
    "student_data[:,18] = activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nursery = student_data[:,19]\n",
    "nursery = np.where(nursery==0, -1, nursery)\n",
    "student_data[:,19] = nursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher = student_data[:,20]\n",
    "higher = np.where(higher==0, -1, higher)\n",
    "student_data[:,20] = higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet = student_data[:,21]\n",
    "internet = np.where(internet==0, -1, internet)\n",
    "student_data[:,21] = internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic = student_data[:,22]\n",
    "romantic = np.where(romantic==0, -1, romantic)\n",
    "student_data[:,22] = romantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing the nominal and numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I don't think this warning is THAT concerning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "temp = student_data[:,[2,14,29,30,31]]\n",
    "Standardized = scaler.fit_transform(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not sure about the -0.0 for the mean..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Mean:', round(Standardized.mean()))\n",
    "print('Standard deviation:', Standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data[:,[2,14,29,30,31]] = Standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-of-C encode nominal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}0 & 1 & 2 & 3 & 4\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[0  1  2  3  4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADYAAAAVCAYAAAANfR1FAAAABHNCSVQICAgIfAhkiAAAA0hJREFUWIXt11uIVlUUB/CfzTjOZGVFRnSjpBIjQgsLI+fFMiiCbg89BF1QCCwiQbKgml4iDKIhesgIaiIisiaR6N6DGCVdpofKrpaJly6Y0UWn1OlhrY/55rjP902YSNQfDpuz/nutvdbee611Dv8xPIHvMflAO9IGZ2MEC8YzeTb2YHENPw+D2IphbMYruHgctq9JR1o5MwELsRa/4je8hxtxUGH+ILbgkHaLv4rt6Clwy9KpjViOe/EoPkiuFU5Iu79oHdhTyX+XtvvxScoGCvPPSe6OVoufJk5reYFbmAYeR1eBn9jC7gS8jq9wv/rALk9uPY5qkndhVXJXFPTWYYPyiYL7UnleRT5J5NwG5aDa4RaxYb3oUx/YQHKLCtzM5N4scHcnd1FDUI3wAuzGOxX5hZiK59PBS3BbOjynPh4wQ2xYP1a3mXtMjusLXEM2196b+1aTn6CziZwsdmWdSNhmzM5xJ4ZwRoVfjavwQ0XeiSfxrTY5kPgxx5ML3LQmm9PwaRP3bo69DUHziR2HDlFhqjg6xyXiyOfiUJwpik0vni3o3YVZuA47SpFU8GKOi3Fkk3wi7ml6P6Ki97PY9BNLRuek088UuEeS24mTKtzBokqOGHstz8Uue1fLPvU51oGXk9+a6/bjY2wTOT6StqvYlOth7Ik1drS7oLQ9xyF8U+F+F32MKL3EdRnA57izYK8Ou3EploprfW0+X+A80SqIQlZFj5pbcazYjTUF7obkXqpxqFHCl+b74UYbcbvnwRqbVXSLD4JqHhMHtEe0E4wtHltSaXpB8Y104vQmI81oFJOvcxzGYzUOniXybg0+w9s186q4WlTDpwvcdNErP6xTXiECOKXArUzu1op8vgj0J0wZh4N9Wn95HFaQzRSbvk3crCquT5s3NQSdlQnP4UrR6L6scIvETj8g+tiQKMuXidxYIKrTvuI1kSsfiZyakevtEPm3uaAzP31YWWe0S3yjra3hp+IhUZ3+EH1n0GjRGA/6tD6xJXhfFKxh0ZgfxvE186eIoF9ot/DtufCsv+HsgcTNwt/z203sFieyan979A+gR1zNFVWiozB5l/gNmST+g/7cr67tG04V13WZ0V77P/6V+AuPmNlOvZMtIAAAAABJRU5ErkJggg==\n",
      "text/latex": [
       "$$\\left ( 649\\right )$$"
      ],
      "text/plain": [
       "(649,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([list([array([1., 0., 0., 0., 0.], dtype=float32)]),\n",
       "       list([array([1., 0., 0., 0., 0.], dtype=float32)]),\n",
       "       list([array([1., 0., 0., 0., 0.], dtype=float32)]),\n",
       "       list([array([0., 1., 0., 0., 0.], dtype=float32)]),\n",
       "       list([array([0., 0., 1., 0., 0.], dtype=float32)])], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mother's job\n",
    "## Teacher, Health Care, Civil Services, At Home, Other\n",
    "\n",
    "# index of current feature\n",
    "index = 8\n",
    "\n",
    "# unique values this feature can inhibit\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "display(uniqueVals)\n",
    "\n",
    "# convert numerical data into categories\n",
    "shape = uniqueVals.shape[1]\n",
    "categoricalArr = keras.utils.to_categorical(student_data[:,index], shape)\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [categoricalArr[i,:]]\n",
    "display(student_data[:,index].shape)\n",
    "display(student_data[:5,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Father's Job\n",
    "## Teacher, Health Care, Civil Services, At Home, Other\n",
    "index = 9\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "categoricalArr = keras.utils.to_categorical(student_data[:,index], shape)\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [categoricalArr[i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reason for Choosing This School\n",
    "## Close to Home, School Reputation, Course Prefrence, Other\n",
    "index = 10\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "categoricalArr = keras.utils.to_categorical(student_data[:,index], shape)\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [categoricalArr[i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaurdian\n",
    "## Mother, Father, Other\n",
    "index = 11\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "categoricalArr = keras.utils.to_categorical(student_data[:,index], shape)\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [categoricalArr[i,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermometer Encode Nominal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 4, 3], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mother's Education\n",
    "## None, Primary (4th grade), 5th to 9th grade, Secondary, Higher\n",
    "index = 6\n",
    "display(student_data[0:5,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}0 & 1 & 2 & 3 & 4\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[0  1  2  3  4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "display(uniqueVals)\n",
    "shape = uniqueVals.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 0]], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49080613/numpy-thermometer-encoding\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "display(thermArr[0:5,:])\n",
    "display(thermArr[0:5,:shape-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([array([1, 1, 1, 1], dtype=uint8)]),\n",
       "       list([array([1, 0, 0, 0], dtype=uint8)]),\n",
       "       list([array([1, 0, 0, 0], dtype=uint8)]),\n",
       "       list([array([1, 1, 1, 1], dtype=uint8)]),\n",
       "       list([array([1, 1, 1, 0], dtype=uint8)])], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "display(student_data[0:5,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 2, 3], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([list([array([1, 1, 1, 1], dtype=uint8)]),\n",
       "       list([array([1, 0, 0, 0], dtype=uint8)]),\n",
       "       list([array([1, 0, 0, 0], dtype=uint8)]),\n",
       "       list([array([1, 1, 0, 0], dtype=uint8)]),\n",
       "       list([array([1, 1, 1, 0], dtype=uint8)])], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Father's Education\n",
    "## None, Primary (4th grade), 5th to 9th grade, Secondary, Higher\n",
    "index = 7\n",
    "display(student_data[0:5,index])\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "display(student_data[0:5,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travel Time\n",
    "## <15min, 15min - 30min, 30min - 1hour, >1hour\n",
    "index = 12\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Study Time\n",
    "## <2hours, 2hours - 5hours, 5hours - 10hours, >10hours\n",
    "index = 13\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Failures\n",
    "## 0, 1, 2, 3, 4+\n",
    "index = 14\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Free Time\n",
    "## 1 - very low to 5 - very high\n",
    "index = 24\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Going Out With Friends\n",
    "## 1 - very low to 5 - very high\n",
    "index = 25\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Weekend Alcohol Consumption\n",
    "## 1 - very low to 5 - very high\n",
    "index = 26\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Workday Alcohol Consumption\n",
    "## 1 - very low to 5 - very high\n",
    "index = 27\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]\n",
    "    \n",
    "# Current Health Status\n",
    "## 1 - very low to 5 - very high\n",
    "index = 28\n",
    "uniqueVals = Matrix(np.unique(student_data[:,index])).T\n",
    "shape = uniqueVals.shape[1]\n",
    "thermArr = np.array([student_data[:,index]], dtype=np.uint8)\n",
    "thermArr = np.fliplr(np.unpackbits((1 << thermArr) - 1).reshape(-1,8))\n",
    "for i in range (649):\n",
    "    student_data[i,index] = [thermArr[i,:shape-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert results to one-hot encoding\n",
    "#### the actual output vector doesn't include at least one example of each possible grade so I made a vector of all possibilities for to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_results = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a weird error in the training below\n",
    "## am I storing the data wrong here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = student_data[:,32]\n",
    "y = keras.utils.to_categorical(results, len(possible_results))\n",
    "x = student_data[:,:32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data is now preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x.shape[1]\n",
    "output_size = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the hidden layer\n",
    "model.add(keras.layers.Dense(400,input_dim=input_size,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(200,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "model.add(keras.layers.Dense(output_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 400)               13200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                4020      \n",
      "=================================================================\n",
      "Total params: 97,420\n",
      "Trainable params: 97,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-257-14d63e0e8f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y,batch_size = 32, epochs = 160, verbose = 0, validation_split = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train'], loc='upper left')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x,y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc ='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc ='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-91ee1538007e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCAs of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def func(X):\n",
    " #   return X\n",
    "#xFunc = np.apply_along_axis(func,0,x)\n",
    "\n",
    "\n",
    "#U,S,V = np.linalg.svd(xFunc,full_matrices=True)\n",
    "\n",
    "# Plot the percent of variance accounted for by each feature\n",
    "#plt.plot(100.0*S/np.sum(S))\n",
    "#plt.ylabel(\"Percent Variance\")\n",
    "#plt.xlabel(\"Singular Value\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-172a0b0aa663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://www.youtube.com/watch?v=Lsue2gEM9D0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpca_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 381\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/nfshome/apps/python-3.6.7/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=Lsue2gEM9D0\n",
    "pca=PCA()\n",
    "pca.fit(x)\n",
    "pca_data = pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-61f223ddbf32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mper_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtick_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"% var\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals = 1)\n",
    "labels = [str(i) for i in range (1, len(per_var)+1)]\n",
    "\n",
    "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel(\"% var\")\n",
    "plt.xlabel(\"PC\")\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
